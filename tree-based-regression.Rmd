---
title: "Analisis Prediktif Harga Rumah Menggunakan Tree Based Algorith"
author: "Moh. Rosidi"
date: "7/20/2020"
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: no
    df_print: paged
    theme: yeti
    highlight: textmate
    css: assets/style.css
  pdf_document:
    toc: yes
    toc_depth: '3'
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Pengantar



# Dataset Ames



# Persiapan {.tabset}

## Library

```{r import-lib, cache=TRUE}
# library pembantu
library(plyr)
library(e1071)
library(foreach)
library(import)
library(tidyverse)
library(rsample)
library(recipes)
library(DataExplorer)
library(skimr)
library(modeldata)

# library model
library(caret) 
library(rpart)
library(ipred)
library(randomForest)
library(gbm)

# paket penjelasan model
library(rpart.plot)  
library(vip)         
```


## Import Dataset

```{r import-data, cache=TRUE}
data("ames")
```


# Data Splitting

```{r data-split, cache=TRUE}
set.seed(123)

split  <- initial_split(ames, prop = 0.7, strata = "Sale_Price")
ames_train  <- training(split)
ames_test   <- testing(split)
```


```{r target-vis, cache=TRUE}
# training set
ggplot(ames_train, aes(x = Sale_Price)) + 
  geom_density() 
# test set
ggplot(ames_test, aes(x = Sale_Price)) + 
  geom_density() 
```


# Analisis Data Eksploratif

## Ringkasan Data

```{r glimpse, cache=TRUE}
glimpse(ames_train)
```

```{r skim, cache=TRUE}
skim(ames_train)
```

```{r missing-vis, cache=TRUE}
plot_missing(ames_train)
```


## Variasi

```{r hist, cache=TRUE}
plot_histogram(ames_train, ncol = 2L, nrow = 2L)
```

```{r bar, cache=TRUE}
plot_bar(ames_train, ncol = 2L, nrow = 2L)
```

```{r nzv, cache=TRUE}
nzvar <- nearZeroVar(ames_train, saveMetrics = TRUE) %>% 
  rownames_to_column() %>% 
  filter(nzv)
nzvar
```

```{r wt-nzv, cache=TRUE}
without_nzvar <- select(ames_train, !nzvar$rowname)
skim(without_nzvar)
```

```{r count-nominal, cache=TRUE}
# MS_SubClass 
count(ames_train, MS_SubClass) %>% arrange(n)
# Neighborhood
count(ames_train, Neighborhood) %>% arrange(n)
# Neighborhood
count(ames_train, Exterior_1st) %>% arrange(n)
# Exterior_2nd
count(ames_train, Exterior_2nd) %>% arrange(n)
```

```{r, cache=TRUE}
plot_bar(without_nzvar)
```


## Kovarian

```{r heatmap, cache=TRUE}
plot_correlation(ames_train, type = "continuous", 
                 cor_args = list(method = "spearman"))
```


# Target and Feature Engineering

```{r preprocess, cache=TRUE}
blueprint <- recipe(Sale_Price ~., data = ames_train) %>%
  # feature filtering
  step_nzv(all_nominal()) %>%
  # label encoding
  step_integer(dplyr::matches("Exterior|Neighbor|Sub|Qual|Cond|QC|Qu|Type")) %>%
  # standardization
  step_center(all_numeric(), -all_outcomes()) %>%
  step_scale(all_numeric(), -all_outcomes())
blueprint
```

```{r prep, cache=TRUE}
prepare <- prep(blueprint, training = ames_train)
prepare
```

```{r baked, cache=TRUE}
baked_train <- bake(prepare, new_data = ames_train)
baked_test <- bake(prepare, new_data = ames_test)
baked_train
```

```{r, cache=TRUE}
skim(baked_train)
```


# Decision Tree Model

## Validasi Silang dan Parameter Tuning

```{r, cache=TRUE}
# spesifikasi metode validasi silang
cv <- trainControl(
  # possible value: "boot", "boot632", "optimism_boot", "boot_all", "cv", 
  #                 "repeatedcv", "LOOCV", "LGOCV"
  method = "cv", 
  number = 10,
  search = "random",
  # repeats = 5,
  allowParallel = TRUE
)
```


```{r, cache=TRUE}
system.time(
dt_fit_cv <- train(
  blueprint,
  data = ames_train,
  method = "rpart",
  trControl = cv,
  tuneLength = 10,
  metric = "RMSE"
  )
)

dt_fit_cv
```

```{r dt-rmse, cache=TRUE}
dt_rmse <- dt_fit_cv$results %>%
  arrange(RMSE) %>%
  slice(1) %>%
  select(RMSE) %>% pull()

dt_rmse
```


```{r dt-cv-vis, chace = TRUE}
# visualisasi
ggplot(dt_fit_cv)
```


## Model Akhir

```{r dt-final, cache=TRUE}
dt_fit <- dt_fit_cv$finalModel
```


```{r dt-vis, cache=TRUE}
# visualisasi
rpart.plot(dt_fit)
```

```{r dt-res-vis, cache=TRUE}
pred_train <- predict(dt_fit, baked_train)
residual <- mutate(baked_train, residual = Sale_Price - pred_train)

# resiual vs actual
sp <- ggplot(residual, aes(x = Sale_Price, y = residual)) +
  geom_point()
# residual distribution
hs <- ggplot(residual, aes(x = residual)) +
  geom_histogram()

gridExtra::grid.arrange(sp, hs, ncol = 2)
```


```{r dt-rmse-test, cache=TRUE}
# prediksi Sale_Price ames_test
pred_test <- predict(dt_fit, baked_test)

## RMSE
RMSE(pred_test, baked_test$Sale_Price, na.rm = TRUE)
```


## Tingkat Kepentingan Variabel

```{r dt-vip, cache=TRUE}
vip(dt_fit_cv, num_features = 10)
```


# Bagging

## Validasi Silang

```{r bag-cv, cache=TRUE}
# spesifikasi metode validasi silang
cv <- trainControl(
  # possible value: "boot", "boot632", "optimism_boot", "boot_all", "cv", 
  #                 "repeatedcv", "LOOCV", "LGOCV"
  method = "cv", 
  number = 10,
  # repeats = 5,
  allowParallel = TRUE
)
```


```{r bag-fit, cache=TRUE}
system.time(
bag_fit_cv <- train(
  blueprint,
  data = ames_train,
  method = "treebag",
  trControl = cv,
  importance = TRUE
  )
)

bag_fit_cv
```

```{r bag-rmse, cache=TRUE}
bag_rmse <- bag_fit_cv$results %>%
  arrange(RMSE) %>%
  slice(1) %>%
  select(RMSE) %>% pull()

bag_rmse
```

## Model AKhir


```{r bag-final, cache=TRUE}
bag_fit <- bag_fit_cv$finalModel
```


```{r bag-res-vis, cache=TRUE}
pred_train <- predict(bag_fit, baked_train)
residual <- mutate(baked_train, residual = Sale_Price - pred_train)

# resiual vs actual
sc <- ggplot(residual, aes(x = Sale_Price, y = residual)) +
  geom_point()
# residual distribution
hs <- ggplot(residual, aes(x = residual)) +
  geom_histogram()

gridExtra::grid.arrange(sc, hs, ncol = 2)
```

```{r bag-rmse-test, cache=TRUE}
# prediksi Sale_Price ames_test
pred_test <- predict(bag_fit, baked_test)

## RMSE
RMSE(pred_test, baked_test$Sale_Price, na.rm = TRUE)
```

## Tingkat Kepentingan Variabel

```{r bag-vip, cache=TRUE}
vip(bag_fit_cv, num_features = 10)
```

# Random Forest

## Validasi Silang dan Parameter Tuning

```{r rf-cv, cache=TRUE}
# spesifikasi metode validasi silang
cv <- trainControl(
  # possible value: "boot", "boot632", "optimism_boot", "boot_all", "cv", 
  #                 "repeatedcv", "LOOCV", "LGOCV"
  method = "cv", 
  number = 10,
  search = "random",
  # repeats = 5,
  allowParallel = TRUE
)
```

```{r rf-fit, cache=TRUE}
# membuat model
system.time(
rf_fit_cv <- train(
  blueprint,
  data = ames_train,
  method = "parRF",
  trControl = cv,
  tuneLength = 20,
  metric = "RMSE"
  )
)

rf_fit_cv
```

```{r rf-rmse, cache=TRUE}
rf_rmse <- rf_fit_cv$results %>%
  arrange(RMSE) %>%
  slice(1) %>%
  select(RMSE) %>% pull()
```

```{r rf-vis, chace = TRUE}
# visualisasi
ggplot(rf_fit_cv)
```

## Model AKhir

```{r rf-final, cache=TRUE}
rf_fit <- rf_fit_cv$finalModel
```

```{r rf-resid-vis, cache=TRUE}
pred_train <- predict(rf_fit, baked_train)$prediction
residual <- mutate(baked_train, residual = Sale_Price - pred_train)

# resiual vs actual
sc <- ggplot(residual, aes(x = Sale_Price, y = residual)) +
  geom_point() 
# residual distribution
hs <- ggplot(residual, aes(x = residual)) +
  geom_histogram()

gridExtra::grid.arrange(sp, hs, ncol = 2)
```

```{r rf-rmse-test, cache=TRUE}
# prediksi Sale_Price ames_test
pred_test <- predict(rf_fit, baked_test)$prediction

## RMSE
RMSE(pred_test, baked_test$Sale_Price, na.rm = TRUE)
```

## Tingkat Kepentingan Variabel

```{r rf-vip, cache=TRUE}
vip(rf_fit_cv, num_features = 10)
```

# Boosting

## Validasi Silang dan Parameter Tuning

```{r boost-cv, cache=TRUE}
# spesifikasi metode validasi silang
cv <- trainControl(
  # possible value: "boot", "boot632", "optimism_boot", "boot_all", "cv", 
  #                 "repeatedcv", "LOOCV", "LGOCV"
  method = "cv", 
  number = 10, 
  # repeats = 5,
  allowParallel = TRUE
)
```

```{r boost-grid, cache=TRUE}
hyper_grid <- expand.grid(
  n.trees = 6000,
  shrinkage = 0.01,
  interaction.depth = c(3, 5, 7),
  n.minobsinnode = c(5, 10, 15)
)
```

```{r boost-fit, cache=TRUE}
system.time(
gb_fit_cv <- train(
  blueprint,
  data = ames_train,
  method = "gbm",
  trControl = cv,
  tuneGrid = hyper_grid,
  verbose = FALSE,
  metric = "RMSE"
  )
)

gb_fit_cv
```

```{r boost-rmse, cache=TRUE}
rf_rmse <- gb_fit_cv$results %>%
  arrange(RMSE) %>%
  slice(1) %>%
  select(RMSE) %>% pull()
```

## Model Akhir

```{r boost-final, cache=TRUE}
gb_fit <- gb_fit_cv$finalModel
```


```{r boost-resid, cache=TRUE}
pred_train <- predict(gb_fit, n.trees = gb_fit$n.trees,
                      baked_train)
residual <- mutate(baked_train, residual = Sale_Price - pred_train)

# resiual vs actual
sc <- ggplot(residual, aes(x = Sale_Price, y = residual)) +
  geom_point() 
# residual distribution
hs <- ggplot(residual, aes(x = residual)) +
  geom_histogram()

gridExtra::grid.arrange(sp, hs, ncol = 2)
```

```{r boost-test-rmse, cache=TRUE}
# prediksi Sale_Price ames_test
pred_test <- predict(gb_fit, n.trees = gb_fit$n.trees,
                     baked_test)

## RMSE
RMSE(pred_test, baked_test$Sale_Price, na.rm = TRUE)
```

## Tingkat Kepentingan Variabel

```{r boost-vip, cache=TRUE}
vip(gb_fit_cv, num_features = 10)
```











_test, ames_test$Sale_Price, na.rm = TRUE)
```

## Tingkat Kepentingan Variabel

```{r, cache=TRUE}
vip(gb_fit, num_features = 10)
```



